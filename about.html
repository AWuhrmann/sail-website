---
layout: default
title: "About"
description: "Learn about EPFL Safe AI Lausanne's mission, values, and the community working towards responsible AI development."
---

<section class="page-header">
    <div class="container">
        <h1>About SAIL</h1>
        <p>Building a community dedicated to AI safety research and education at EPFL</p>
    </div>
</section>

<main class="container">
    <section class="section">
        <h2>Our Mission</h2>
        <p>EPFL Safe AI Lausanne (SAIL) was founded on the belief that as artificial intelligence systems become increasingly powerful and pervasive, ensuring their safety and alignment with human values is one of the most important challenges of our time.</p>
        
        <p>We are a student-led organization at EPFL committed to fostering research, education, and community engagement around AI safety. Our goal is to create a vibrant ecosystem where students, researchers, and professionals can collaborate on making AI systems safer and more beneficial for humanity.</p>
    </section>

    <section class="section">
        <h2>What We Do</h2>
        <div class="cards-grid">
            <div class="card">
                <h3>ğŸ”¬ Research Excellence</h3>
                <p>We facilitate high-quality research projects in AI safety, connecting students with leading labs at EPFL. Our members have published papers at top venues like NeurIPS and contributed to advancing the field.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ“š Knowledge Sharing</h3>
                <p>Through our bi-weekly reading group, workshops, and seminars, we create opportunities for deep engagement with AI safety literature and cutting-edge research developments.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ¤ Community Building</h3>
                <p>We bring together diverse voices from across EPFL and beyond, fostering collaborations between computer scientists, ethicists, policy researchers, and domain experts.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ¯ Practical Impact</h3>
                <p>We focus on research that can have real-world impact, working on problems like interpretability, robustness, alignment, and governance that matter for deployed AI systems.</p>
            </div>
        </div>
    </section>

    <section class="section">
        <h2>Our Values</h2>
        <div style="max-width: 800px; margin: 0 auto;">
            <div class="card" style="margin-bottom: 2rem;">
                <h3>ğŸ”¬ Scientific Rigor</h3>
                <p>We believe in evidence-based approaches to AI safety. Our work is grounded in solid technical foundations, empirical evaluation, and peer review.</p>
            </div>
            
            <div class="card" style="margin-bottom: 2rem;">
                <h3>ğŸŒ Global Perspective</h3>
                <p>AI safety is a global challenge that requires diverse perspectives. We welcome members from all backgrounds and actively seek to understand how AI impacts different communities.</p>
            </div>
            
            <div class="card" style="margin-bottom: 2rem;">
                <h3>ğŸ¤² Collaborative Spirit</h3>
                <p>The best solutions emerge from collaboration. We work closely with other AI safety organizations, research labs, and the broader community to share knowledge and coordinate efforts.</p>
            </div>
            
            <div class="card" style="margin-bottom: 2rem;">
                <h3>ğŸ“ˆ Long-term Thinking</h3>
                <p>While we work on immediate challenges, we also consider the long-term implications of AI development and strive to contribute to solutions that remain relevant as capabilities advance.</p>
            </div>
        </div>
    </section>

    <section class="section">
        <h2>Research Areas</h2>
        <p>Our members work across a wide range of AI safety topics, reflecting the interdisciplinary nature of the field:</p>
        
        <div class="cards-grid">
            <div class="card">
                <h3>ğŸ” Interpretability</h3>
                <p>Understanding how AI systems make decisions through techniques like mechanistic interpretability, feature visualization, and explanation methods.</p>
            </div>
            
            <div class="card">
                <h3>âš–ï¸ Alignment</h3>
                <p>Ensuring AI systems pursue intended objectives through reward modeling, constitutional AI, and human feedback approaches.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ›¡ï¸ Robustness</h3>
                <p>Making AI systems reliable under distribution shift, adversarial examples, and unexpected conditions.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ“Š Evaluation</h3>
                <p>Developing benchmarks and methods to assess AI capabilities, limitations, and potential risks before deployment.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ›ï¸ Governance</h3>
                <p>Understanding policy implications, developing governance frameworks, and studying the societal impact of AI systems.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ”’ Security</h3>
                <p>Protecting AI systems from misuse, studying dual-use research, and developing secure deployment practices.</p>
            </div>
        </div>
    </section>

    <section class="section">
        <h2>Achievements</h2>
        <div class="cards-grid">
            <div class="card">
                <h3>ğŸ“„ Publications</h3>
                <p>Our members have contributed to {{ site.data.projects.sail_projects.size }} research projects, including papers accepted at NeurIPS and other top-tier venues.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ“ Student Development</h3>
                <p>We've supported students in finding research opportunities, applying to graduate programs, and launching careers in AI safety.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ¤ Partnerships</h3>
                <p>Active collaborations with EPFL labs including MLO, NLP, and partnerships with organizations like MATS and other AI safety groups.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ“ˆ Community Growth</h3>
                <p>From a small group of interested students to a recognized organization with regular events, research output, and growing influence in the AI safety community.</p>
            </div>
        </div>
    </section>

    <section class="section">
        <h2>Join Our Community</h2>
        <p>We welcome anyone interested in AI safety, regardless of background or experience level. Whether you're a undergraduate curious about the field, a graduate student looking to contribute to research, or a professional seeking to make an impact, there's a place for you in our community.</p>
        
        <div class="cards-grid">
            <div class="card">
                <h3>ğŸš€ For Students</h3>
                <p>Get involved in cutting-edge research, present at conferences, and build skills that will serve you throughout your career in AI safety.</p>
            </div>
            
            <div class="card">
                <h3>ğŸ§‘â€ğŸ”¬ For Researchers</h3>
                <p>Connect with collaborators, share your work, and contribute to shaping the future direction of AI safety research.</p>
            </div>
            
            <div class="card">
                <h3>ğŸŒ For Everyone</h3>
                <p>Participate in discussions, attend our events, and help build a community dedicated to beneficial AI development.</p>
            </div>
        </div>
        
        <div style="text-align: center; margin-top: 3rem;">
            <a href="{{ '/contact/' | relative_url }}" class="cta-button">Get Involved Today</a>
        </div>
    </section>

    <section class="section">
        <h2>Connect With Us</h2>
        <p>Follow our progress and stay updated with the latest in AI safety research and community activities:</p>
        
        <div style="display: flex; justify-content: center; gap: 2rem; flex-wrap: wrap; margin-top: 2rem;">
            <a href="mailto:lausanne@aisafety.ch" style="color: #ff0000; text-decoration: none;">
                <div style="text-align: center;">
                    <div style="font-size: 2rem;">âœ‰ï¸</div>
                    <div>Email</div>
                </div>
            </a>
            <a href="https://t.me/+5KQ7sfHT51I4Mzhk" target="_blank" style="color: #ff0000; text-decoration: none;">
                <div style="text-align: center;">
                    <div style="font-size: 2rem;">ğŸ’¬</div>
                    <div>Telegram</div>
                </div>
            </a>
            <a href="https://www.linkedin.com/company/safe-ai-lausanne/" target="_blank" style="color: #ff0000; text-decoration: none;">
                <div style="text-align: center;">
                    <div style="font-size: 2rem;">ğŸ’¼</div>
                    <div>LinkedIn</div>
                </div>
            </a>
        </div>
    </section>
</main>